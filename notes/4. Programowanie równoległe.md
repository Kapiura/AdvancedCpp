# Agenda
1. modele pamięci: współdzielonej i rozproszonej; (w tym: które z nich są obsługiwane jako domyślne w technologiach: OpenMP, MPI, std::thread)
2. wyścig i zakleszczenie
3. OpenMP (na czym polega zrównoleglanie kodu w tej technologii, kilka zalet, kilka wad lub ograniczeń)
4. MPI (na czym polega polega zrównoleglanie kodu w tej technologii (czym różni się od OpenMP), jak wygląda komunikacja, jak się kompiluje i uruchamia programy)
5. Co reprezentują klasy std::thread, std::mutex, std::lock_guard, std::unique_lock
6. promise / future
7. zrównoleglanie kodu przy pomocy std::async
8. do czego służy std::condition_variable? (dlaczego i do czego potrzebujemy wraz z tym obiektem także muteksu, uniqe_lock i współdzielonej zmiennej?)
9. execution policy
10. co to są operacja atomowe?
11. Do czego służą muteksy i sekcje krytyczne?

## Procesor ma rdzenie :)
A jak taki rdzen wyglada no roznie
Ale ten z przykładu ma np 
- 2 wątki - programy
- 4 operacje na intach
- 4 operacje adresowe 
- 8 operacji na float lub 4 na double
I taki 4-rdzeniowy moze wykonywac 40 operacji arytmetycznych na raz

Jak wykorzystac TAKA MOC>????
- uruchomienie klilku programow na  raz i zaufac systemowi
- Napisac program dzialajacy na kilku rdzeniach i wykorzystać specyfikacje
	- nie da sie tego zautomatyzowac calkowiecie

Po co
- mozna zrobic wiecej przy takim samym poborze prądu
- skórcenie fizycznego czasu obliczęń
- możliwość rozwiązywania wiekszych problemów
- Uzyskanie zasbow niemozliwych dla jednego komputera
- Symulacje
- Automatyczne przyśpieszanie działania programow współbieznych

# Przetwarzanie
- Szeregowe
	- robimy po kolei dane zadania
- Współbiezne:
	- robimy czesc jednego zadania czesc drugiego itd
- Równoległe
	- W tym samym czasie wykonujemy szeregowo zadania
- Równoległe i współbieżnie
	- robimy w tym samym czasie male kawalki programow

# Wielozadaniowość
- preemptive multitasking
- Współpraca
- Możliwośc wykonywania wielu operacji jednocześnie
- Lepsze wykorzystanie architektury

Zrównoleglanie - niezależne strumienie instrukcji MIMD
Wektoryzacja - te same instrukcje na wielu danych SIMD

SISD - Single Instruction Single Data
SIMD - Single instruction Mulitple data
MIMD - Multiple Instruction Multiple Data

# Proces
- program załadowany do pamięci operacynej
- System operacyjny przydziela zasoby oraz separuje procesy - wirtualizacja pamieci operacyjnej

# Wątek
- fragment procesu wykonywany współbieżnie w ramach procesu
- w jednym procesie mozna byc wiele watków
- wątki współdzielą zasoby systemowe
- można wątki łatwo tworzyć i niszczyć
- mogą się komunikować bezpośrednio bez pośrednictwo systemu operacyjnego
# Fiber
- Funkcja ktora mozna przerwac i pozniej wrocic
# Modele pamięci
- Wpółdzielona
	- wszystkie jednostki maja bezpośredni dostęp do tej samej pamieci RAM
	- Komputery wielordzeniowe/wieloprocesorowe
- Rozproszona
	- Część jednak obliczeniowych nie ma bezprosredniego dostępu do pamięci RAM innych jednostek
	- klastry obliczeniowe


# Prawo Ahmdala
Polega na obliczeniu przyspieszenia wykonywania zadan rownolegle

# Prawo Gustafona
- założenie ze kazdy wezeł obliczeniowy będzie wykorzystany pod korek


# Race Condition Wyścig
- Dwa wątki nie widzą siebie, operują na tym samym obiekcie 
- Nie wiemy co jeden zrobi z drugim
- Nie wiemy kto jest pierwszy
- Nie wiemy co sie stanie z obiektem
# Deadlock zakleszczenie
- Dwa wątki blokują sie nawzajem, czekajac na zasoby ktore sa juz zajete przez siebie nawzajem
- program wisi
# Sekcja krytyczna
- Watek bierze dostep do zasobu
- Blokuje innym watkow dostepu do niego, przez co inne musza czekac
- zapobiega to wyscigowi
- Zrobi cos z zasobami i odblokowuje zasob
- Slowa kluczowe:
	- mutex
	- lock
	- criticial section
# Operacja/zmienna atomowa
- Operacja ktora nie moze zostac przerwana i ktorej postep podczas kolejnych faz jej wykonywania nie jest widoczny dla innych wątków az do jej zakończenia -  eliminacja wyscigu
- Zmienna atomowa to zmienna na ktorej wszystkie operacje sa atomowe
# Asynchronicznosc i synchronicznosc
- Synchroniczny
	- zachowuje sie deterministycznie znajac jego stan w chwili t mozna przewidziec jego stan w chwili t+1
- Asynchroniczny
	- Dziala niedetrministycznie
	- zaleznosc od dyspozytora scheduler
	- wynik programu moze byc niedetrminstyczny
# Granularity  - ziarno suchar reference
- Fine-grained parallelism
	- Problem rozbity na bardzo duzo malych podobnych zadan
- Coarse-grtained parallelism 
	- Problem rozbity na mala liczbe roznych niezaleznych od siebie zadan
- Embarrassingly parallel problem
	- Zadania sa od siebie niezalezne
# Latencja - przepustowość
- Latencja - opóźnienie - lag
- Jak dlugo trwa otwieranie kurka
- Informuje o maksyumalnym strumieniu przepusczanym przez urzadzenie

# OpenMP
- Kompialtor automatycznie zrownolegla kod
- Technologia otwarta

- Rozszerzenie kompilatora - nie zmienia sie skladnia jezyka programowania
- `#include <omp.h>`
- Zmienne środowiskowe

- Ma być efektywne w działaniu oraz łatwe w nauce i stosowanie
- OpenMP ma chowac trudnosci związane z programowniem współbieżnym
- Wszystko odbywa sie za pomoca `#pragma`
- Kompilacja wymaga flagi `-fopenmp`
```
#include <iostream>
#include <omp.h>

int main()
{
	std::cout << "Witaj swiecie\n";
#pragma omp parallel
{
#pragma omp single
	std::cout << "Uruchomiono " << omp_get_num_threads() << " watkow\n";
#pragma omp for
	for(int i = 0; i < 10; i++)
	{
#pragma omp critical
		std::cout << "i = " << i << ", watek " << omp_get_thread_num() << "\n";
	}
}
std::cout << "Zegnam\n";
}
```
- Wszystkie pragmy mają postać `#pragma omp argument(y)`
- Każda pragma działa na jedną instrukcje, może być blokowa {}
- Plus jest taki ze bez flagi taki program dziala szeregowo, bez modyfkacji zrodel

- Uruchamianie puli watkow wspolbieznych `#pragma omp parallel`
- `#pragma omp single`
	- wykonywana operacje przez jeden watek nie wiadomo jaki
- `#pragma omp master`
	- operacja wykonywana przez watek nr 0
- `#pragma omp critical`
	- definicja sekcji krytycznej
	- zastepuje mutex lock unlock
- `#pragma omp for`
	- Instrukcja wykonywana przez grupe watkow
Jest ich wiecej i do kazdego mozna dac jakies argumenty ale tym sie czlowiek interesuje jak dopiero chce cos przy uzyciu tego pisac

# Zmienne srodowiskowe
są tam jakies ale to jak wyzej
# Kompilacja warunkowa
- jesli nasz kompilator pracuje w trybie OpenMP to zdefiniowal makro \_OPENMP

- Łatwy
- nie wymaga projektowania programu jako rownoleglego
- Mozna zamienic szeregowy w rownoglely program

# MPI
Message Passing Interface
- Biblioteka do programowania wspolbieznego z pamiecia rozproszona
Przyklad programu
```
#include <iostream>
#include <mpi.h>

int main(int argc, char* argv[])
{
	MPI_Init(&argc, &argv);
	int rank;
	MPI_Comm_rank(MPI_COMM_WORLD, &rank);
	std::cout << "Hello! from process nr " << rank << "\n";
	MPI_Finalize();
}
```
- Instaluje się przy pomocą jednej z bibliotek
	- OpenMPI
	- MPICH
- Kompilacja 
	- `mpicxx prog.cpp`
	- `mpic++ prog.cpp`
- Uruchomienie
	- `mpirun -np 4 ./a.exe`
	- `mpirun -np 10 --hosts master,slave1,slave2`
	- liczba procesow oraz maszyny
	- mozna tez dodac plik konfiguracyjny `host_file`

- Konfiguracja serwerów - wspólny dysk sieciowy
- przez ssh
- testy mozna wykonac przez scp i ssh

- Ten sam program wtedy uruchamia sie jako niezalezne procesy na tej samie lub roznych maszynach
- Procesy synchronizuja sie poprzez komunikaty MPI
- Nie ma wspolnej pamieci

- Jest tutaj możliwy wyścig - poprzez przedwcześnie używając bufory operacji nieblokujących
- Zakleszczenie - można uzyskać niemal każdą funkcja MPI - Tam tez sa bariery

- Rozne rodzaje odbiory i wysylania
	- Broadcast
		- Wysylanie jednej wiadomnosci do wszystkich
	- Scatter
		- rozdzielanie danych z wielu procesow do jednego
	- Gather
		- zbieranie danychz wielu procesow dojednego
	- Allgather
		- to samo co gather ale trafia to do wszytkich procesow

- Tutaj duzo moze zalezytc od latencji oraz przepustowosci 
	- Latencja - czas potrzebny do nawaizania polaczaenia i otwarcia kanalu 
	- Przepustowosc - predkosc transferu
# Porownanie
| OpenMP                                                   | MPI                                |
| -------------------------------------------------------- | ---------------------------------- |
| Wbudowane w kompilator                                   | Biblioteka i to dwie rozne         |
| Dyrektywy, biblioteka, zmienne srodowiskowe              | Biblioteka                         |
| pamiec wspoldzielona                                     | Pamiec rozproszona                 |
| watki                                                    | Procesy                            |
| fork&join                                                | Procesy sa tworzone raz            |
| Prosta kompilacja                                        | Nakladka na kompilator             |
| Mozna taki program uruchomic szeregowo                   | Specjalnyu program do uruchamiania |
| Dane pruwatne i wspoldzielone                            | Dane prywatne                      |
| Mozliwy wyscig => sekcje krytycznbe, operacje atomowe... | Nie potrzeba sekcji krytycznych    |
# Ciag dalszy
- Maszyny z pamiecia wspoldzielona
	- latwa wymiana danych miedzy watkami
- wielozadaniowosc z wywlaszczeniem
	- kazdy watek wykonuje sie we wlasnym tempie

- Watki tego samego procesu maja dostep do tej samej pamieci RAM

- Główną trudnością jest typ ze nie wiemy kiedy nasz wątek zostanie wywłaszczony
- Program moze stac sie nieokielznany

# Potezna wspolbieznosc w cpp
`#include <thread>`
- Definiujemy obiekt zarzadzajacy funkcja wywolana wspolbieznie
- `std::thread th(&mojaKoxFunkcja)`
- Pozniej trzeba sycnhronizowac z watkiem glownym
- `th.join();`
## Zasada Fork&Join
- Na pocztku rozgaęziamy zadan na mniejsze czesci i pozniej je scalamy join
```
#include <iostream>
#include <thread>

void task(int id) {
    std::cout << "Wątek " << id << " działa.\n";
}

int main() {
    std::thread t1(task, 1);
    std::thread t2(task, 2);

    t1.join();
    t2.join();

    std::cout << "Oba wątki zakończone.\n";
    return 0;
}
```

- Funkcja join czeka na zakonczenie funkcji ktora zarzadza dany obiekt i dopiero wtedy konczy swoje dzialanie
- Jest to w pewien sposob bariera dla watku glownego
- jest jedna z metod synchronizacji watku glownego z roboczymi
- Jesli zapomnimy o takim joinie program upada - zrzut pamieci
- Dlaczego nie uzywamy tego w destruktorze
	- jesli gdzies bysmy mieli nwyjatek
	- destruktor uruchomilnby join
	- co tworzy bariere na watku glownym
	- w tym sczasie watek roboczyu mogl czekac na dane z glownego
- Rozwiazaniem jest jthread joinable thread
- w jego destruktorze to sie dzieje
	- jest zgodne z raii
	- wywoalnie join jest bezpieczne
	- uwzlednia synchronizacje awaryjna 
- Jezeli twoj kompialtor obsluguje jthread to uzywaj jesli nie to thread ale musisz uwazac na joiny
- jthread wpisuje sie w raii czyli jestes wtedy koxem
- Zamist funkcji w std::thread moze byc lambda
- Podlegaja move semantrics
- nie mozemy kopiowac watkow
- mozemyu tworzyc grupy watkow nie tylko pojedynczy
- emplace_back tworzy na miejscu od razu przy uzyciu konstrkutora obiekt, nie kopiuje, nie przenosi

- Wyścig - jak juz wspominane bylo kilka procesow moze w tym samyum czasie modyfikowac to samo miejsce lub odczytywac
- Diagnostyka jest trudna wiec lepiej zapobiegac 
- Polega na stosowaniu okreslonych regul programowania

# Thread safety
- Watki musza wywolac funkcje thread-safety czyli
	-  nie uzywaja zmiennych globalnych lub statycznych
	- a jesli tak to mamy mutexy do ochorny
- Niektore funkcje nie sa thread-safe np
	- rand()
	- wszystkie klasyczne operacje wyjsia wejscia

- Altertnatywnie mozna od c++20 uzywac std::osyncstream ktore pozwala uzywac wielowatkowo operacji wyjscia oraz wejscia
- kazdy watek musi wtedy mniec wlasny wrapper

- Valgrind nam nie pomoze w diagnostyce kodu
- jest w kompialtorze thread sanitizer
- jest tez gdb

# Kopiowanie watkow = przenoszenie
- thread jthread - podlegaja move semantics
- nie mozna ich kopiowac

To jak je kopiowac
- musimyu jawnie wskazac ze chcemy do wektora przesunac a nie skopiowac nazwany obiekt l-wartosc
- std::move dzieki temu da sie kinda kopiowac

## Przekazywanie parametrow do watkow
- przez wartość
```
void fun(int i);

int main()
{
	...
	std::jthread th(&fun, i);
}
```
- przez referencje
```
void fun(int &i);

int main()
{
	...
	std::jthread th(&fun, std::ref(i));
}

```
- Konstruktor std::thread zaimplementowano jako variadic tempalte - szablon o dowolnej liczbie parametrow
- `std::ref` i `std::cref` sa wrapperami dla argumentow

Dlaczego taka referenc ja jest niebezpieczna
- przekazujac przez ref lub pointer, tworzymy sytuacje gdy watek moze operwoac bezposrednio na lokalnych zmiennych cudzego watku
- const &
	- to tylko proteza cokowliek to znaczy
	- skad wiemy czy watek glowny nie modyfukuje danych przekazanych innym watkom przez stala referencje


Co używac zamiast &
- kopiowanie danych do watkow roboczych
	- bardzo kosztowne jesli danych jest duzo
- Przesuwanie danych do watkow roboczych
- Mowi sie ze w idealnym swiecie kazdy watek pracuje na wlasnych danych - brak wyscigu


## Jak przekazac dane z watku roboczego
Promise i future
- przydaja sie nam one gdy czekamy na dane z watku jednego do drugiego bez marnowania zasobow, czasu, pradu
- maja tak zwane pasywne czekanie a nie aktywne
- uruchamia sie dopiero jak dostanie dane
- sa one ze soba powiazane
- Future - przyszla wartosc
- Promise to jest kanal pomiedzy watkami
- Zawsze wystepuja w parze

- Z promise sie wyciaga dane za pmoca get_future()
- Te dwie zmienne są połączone shared state
- na poczatku mamy promise w funkcji w watku roboczego ustawiamy wartosc za pomoca set_value
- promise przechodzi w stan zombie i nie mozna juz go uzyc
- wartosc posaida shared state i on przekazuja ja do future w momencie wykonania polecenia get_future()
- one wszystkie sa jednorazowego uzytku
- Pobieramy wartosc przez kanal i tyle, kanal zostaje zamnkiety nawet jesli fizycznie sa to i tak nie mozemy nic z nimi zrobic
```
void my_fun(std::promise<std::string> prms)
{
	// ustawia sobie wartosc na promisie
	prms.set_value(std::string("Ja bez zadnego tryy..\n));
}

int main()
{
	std::promise<std:;string> prms;
	std::future<std:;string> fut = prms.get_future();
	std::jthread th(&my_fun, std::move(prms));
	std::cout << "Main pretends working...\n";
	std::string str = fut.get();
}
```
- Da sie za pomoca nich tez zwracac blad w razie czego, w sensie wyjatek
- Jest dosc standardowa chyba ze musimy przekazac watku do glownego

# wyjatek przed promise::set_value
- nalezy wylapac
- ustawic w obiekcie std::promise funkcja set_exception
	- uzywaj std::current_exception()
jesli nie zdolalismy wywoalc setValue to w takim wypadku ma dodatkowa funkcje
set_exception
i takie wysylamy do watku glownego
wiec promise moze zwrocic wartosc albo wyjatek
- Po ustawieniu wyatku w shared_state obiekt std::future przerywa blokade i zglasza ten wyjakte w swoim watku
przekazuje po prostu obekt wyjatku do future przez shared state

# wyjatek po prosmie set_value :()
- std::promise moze zapisac albo wartosc albo wyjatek ale nie oba na raz
- bo std::future juz mogl zwolnic bareire
wiec tak sie pisze programy zeby tak nie bylo bo sa jednorazwego uzycia


# std::async
- wrapper dla thread i jthread
- pozwala uruchomić funkcję asynchronicznie w oddzielnym wątku lub synchronicznie
- Zwraca future
- future::get zwraca wartosc zwrocona w funkcji wywolanej

- prosty
- liczne niespodzianki w dokumentacji i implementacjach
- latwosc napisania kodu ktory zachowuje sie zle

# std::launch::deferred
- async - natcyhmiastowe uruchomienie funkcji w osobym watku
- deferred - uruchomienie funkcji przy pierwszym wywolaniu wait lub get na obiekcie future
- Brak tego parametru - implementacja wybiera ascyn lu deffered

# std::shared_future
- future wielokrotnego uzytku
- Ale promise moze tylko ustalic stan shared memory tylko raz
	- Przydatne jesli do tych samych danych nalezy dac dostep tym samym watkom

Rozwiązaniem wyścigu sa mutexy
`std::mutex`
- lock i unlock wiadomo - sekcja krytyczna
- ale ma jakies powiazanie z deadlockiem
- bo jak sie rzuci wujatek to dalej blokujemy zmienna nasza
- Wiec mamy `std::lock_guard` Automatycznie blokuje muteks w momencie utworzenia obiektu
- Mamy tez unique_lock - możliwość odblokowania i ponownego blokowania muteksu w trakcie trwania zakresu

Kiedy jakiego uzywac
- std::lock_guard
	- dokladnie 1 mutex w zakresie
- std::scoped_lock
	- 1 lub wiecej muteksow w zakresie
- std::unique_lock
	- np z conditio variable

# Operacje atomowe
- std::atomic jest szybsze niz mutex
- mniej elastyczny
- kazda synchronizacja kosztuje
- proste operacje ktore raz rozpoczete nie moga zostac przerwane

# Zmienne warunkowe
- Condition variable
- obiekt, ktorego mozna uzyc do uspienia watka watkow, dopoki inny watek go nie odblokuje
- blokade zaklada sie funkcja 
	- wait, wait_for, wait_unitl
- argumentem funkcji blokujacych zawsze jest
	- `std::unique_lock(na std::mutex)`
- Blokade znosi wywolanmie na obiekcie metody
	- notify_one
	- notify_all
- Mozna zastosowac predykant
	- `cv.wait(lk, []{ return isready; });`
- wait nie zakończy działania, póki predykat nie będzie miał wartości true

Wybudzenie
- spontaniczne
	- watek moze zostac wybudzony w inny sposob niz przez zmienna warunkowa
- ominiete
	- zmienna warukowa wysyla komunikat ktory nie jest umieszczany w kolejce jesli notify zostalnie wywolane przed wait to zostanie zgubione
# Execution policy
koncepcja odnosi się do sposobu, w jaki algorytmy wykonują swoje operacje na kontenerach danych
równoległe lub zrównoleglone przetwarzanie
może przyspieszyć wykonanie algorytmów
`std::execution::seq` - sekwencyjna
`std::execution::par` - rownolegala
`std::execution::par_unseq` - rownolegla z wektoryacja
`std::execution::unseq`